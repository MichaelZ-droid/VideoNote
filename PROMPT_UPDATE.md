# 提示词优化说明 - 支持多种视频类型

## 🎯 优化目标

**之前的问题**：
- ❌ 提示词预设视频类型为"课程/教学"
- ❌ 使用固定的模板（"课程介绍"、"基础讲解"等）
- ❌ 不考虑视频文件名和实际内容

**现在的改进**：
- ✅ 不预设任何视频类型
- ✅ 让 AI 自动识别视频类型
- ✅ 基于文件名和完整文字稿内容分析
- ✅ 根据不同类型生成相应结构的摘要

## 📋 新的提示词设计

### 1. System Prompt（系统角色）

```
你是一个专业的视频内容分析专家，擅长分析各种类型的视频内容并生成结构化摘要。

你的核心能力：
1. 自动识别视频类型（教学、会议、访谈、新闻、娱乐、纪录片、演讲等）
2. 理解视频的内容主题和叙事结构
3. 识别关键信息点、转折点和重要时刻
4. 提取具体的人物、事件、数据、观点
5. 按照内容的逻辑流程组织摘要
```

**关键改进**：
- 强调"各种类型"而非单一类型
- 明确列出多种视频类型
- 注重"识别"而非"假设"

### 2. User Prompt（用户任务）

新增了**三步分析流程**：

#### 第一步：识别视频类型
```
首先判断这是什么类型的视频：
- 教学/课程（讲解知识、演示技能）
- 会议/讨论（多人对话、决策讨论）
- 访谈/对话（主持人与嘉宾）
- 演讲/分享（单人演讲）
- 新闻/报道（事件报道）
- 纪录片（叙事性内容）
- Vlog/生活记录（个人记录）
- 其他类型
```

#### 第二步：理解内容结构
```
基于视频类型，识别内容的自然分段：
- 教学：引入 → 核心概念 → 示例演示 → 总结
- 会议：开场 → 议题讨论 → 决策 → 行动项
- 访谈：开场介绍 → 问题1 → 问题2 → ... → 结束
- 演讲：开场 → 论点1 → 论点2 → ... → 总结
- 纪录片：背景介绍 → 事件展开 → 转折 → 结论
- Vlog：活动1 → 活动2 → ... → 感想
```

#### 第三步：生成摘要
根据识别的类型和结构，生成适配的摘要

### 3. 输出格式增强

现在要求 AI 返回：
```json
{
  "video_type": "识别的视频类型",
  "summary": [...]
}
```

这样前端可以知道 AI 识别的视频类型。

## 📊 不同类型视频的示例

### 教学视频
```json
{
  "video_type": "教学/课程",
  "summary": [
    {
      "timestamp": "00:00",
      "title": "React Hooks 的三个核心规则",
      "content": "讲解 React Hooks 必须遵守的三个规则：1) 只在函数顶层调用..."
    }
  ]
}
```

### 会议视频
```json
{
  "video_type": "会议/讨论",
  "summary": [
    {
      "timestamp": "00:00",
      "title": "产品迭代计划讨论（张经理主持）",
      "content": "张经理介绍本次会议议题：讨论 Q2 产品迭代计划。参会人员包括..."
    },
    {
      "timestamp": "02:15",
      "title": "李工程师提出技术债务问题",
      "content": "李工程师指出当前系统存在性能瓶颈，数据库查询平均响应时间达 800ms..."
    }
  ]
}
```

### 访谈视频
```json
{
  "video_type": "访谈/对话",
  "summary": [
    {
      "timestamp": "00:00",
      "title": "专访创业者李明：从程序员到 CEO",
      "content": "主持人介绍嘉宾李明，35岁，科技公司 CEO..."
    }
  ]
}
```

### Vlog 视频
```json
{
  "video_type": "Vlog/生活记录",
  "summary": [
    {
      "timestamp": "00:00",
      "title": "东京旅行 Day 1：抵达新宿",
      "content": "早上 9 点从成田机场出发，乘坐 NEX 列车前往新宿。车程约 1 小时..."
    }
  ]
}
```

## 🔄 数据流更新

### 之前的流程
```
用户上传视频
    ↓
提取音频
    ↓
生成固定的"课程"模板摘要（❌ 不看实际内容）
```

### 现在的流程
```
用户上传视频
    ↓
提取音频 + 获取文件名
    ↓
传递给后端：audioPath + audioDuration + videoTitle
    ↓
后端生成文字稿（包含完整时间戳）
    ↓
AI 分析：
  1. 根据文件名推测内容类型
  2. 阅读完整文字稿
  3. 识别视频类型
  4. 理解内容结构
  5. 生成匹配的摘要
```

## 🛠️ 代码改动

### 1. Edge Function
**文件**：`supabase/functions/process-video-summary/index.ts`

**改动**：
- 更新 SYSTEM_PROMPT（不预设类型）
- 更新 USER_PROMPT_TEMPLATE（三步分析法）
- 接收 `videoTitle` 参数
- 根据文件名生成更贴近的模拟数据

### 2. 前端传参
**文件**：`src/lib/videoProcessor.ts` 和 `src/pages/Index.tsx`

**改动**：
- 传递 `videoTitle` 参数给后端
- 让 AI 能够参考文件名理解内容

## 📝 提示词关键要点

### 强调具体性
```
❌ 避免："介绍了基本概念"
✅ 要求："讲解了 React Hooks 的三个核心规则：..."
```

### 提取关键信息
要求包含：
- 人物：谁说了什么，谁做了什么
- 事件：发生了什么，为什么
- 数据：具体的数字、时间、地点
- 观点：核心论点和论据
- 方法：具体的步骤、技巧

### 适应不同结构
不同类型的视频有不同的叙事结构：
- 教学：线性递进
- 会议：议题驱动
- 访谈：问答结构
- Vlog：时间线记录

## 🧪 测试建议

### 测试不同类型视频

1. **上传会议录音**
   - 文件名：`2024年产品规划会议.mp4`
   - 预期：识别为"会议"，按议题分段

2. **上传教学视频**
   - 文件名：`Python入门教程第1课.mp4`
   - 预期：识别为"教学"，按知识点分段

3. **上传 Vlog**
   - 文件名：`日本旅行Day1.mp4`
   - 预期：识别为"Vlog"，按活动分段

4. **上传访谈**
   - 文件名：`创业者访谈-李明.mp4`
   - 预期：识别为"访谈"，按问题分段

## 🔮 集成真实 API 后的效果

当集成阿里云 Paraformer 和 Qwen API 后：

1. **Paraformer** 将提供准确的语音识别文字稿
2. **Qwen** 将基于真实内容识别视频类型
3. AI 能够：
   - 识别视频中的人名、地名、专业术语
   - 理解对话的上下文和逻辑关系
   - 捕捉情感变化和重要时刻
   - 生成贴合内容的标题和摘要

## 📊 对比效果

### 优化前
```
标题：课程介绍：核心技术概览
内容：介绍本次课程的主要内容，涵盖技术基础概念...
```
（所有视频都用"课程"模板）

### 优化后
```
会议类型：
标题：产品规划讨论（张经理主持，5人参会）
内容：讨论 Q2 产品路线图，重点是用户增长策略...

访谈类型：
标题：李明谈创业经历：从程序员到 CEO 的转变
内容：李明分享 2019 年创业初期的挑战，团队从 3 人...

Vlog 类型：
标题：东京旅行第一天：新宿和一兰拉面
内容：上午抵达新宿，入住王子酒店。下午排队 40 分钟...
```

## ✅ 总结

现在系统能够：
1. ✅ 接收视频文件名作为上下文
2. ✅ 不预设任何视频类型
3. ✅ 自动识别内容类型和结构
4. ✅ 生成匹配类型的摘要格式
5. ✅ 提取具体的人物、事件、数据

**这是一个通用的视频摘要系统，而不仅仅是课程摘要工具！** 🎉
